{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0622da-9229-4822-8482-b9b76cd3b107",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://8a95fd7f28d1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://197e20b418a6:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Optimizing Skewness and Spillage</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f529e4b5790>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Optimizing Skewness and Spillage\")\n",
    "    .master(\"spark://197e20b418a6:7077\")\n",
    "    .config(\"spark.cores.max\", 8)\n",
    "    .config(\"spark.executor.cores\", 4)\n",
    "    .config(\"spark.executor.memory\", \"512M\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99724543-fea0-4b89-996d-cf8cea168bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Disable AQE and Broadcast join\n",
    "\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9191ed11-3ca0-4c15-a3ba-a80bc6fbf9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Employee data\n",
    "_schema = \"first_name string, last_name string, job_title string, dob string, email string, phone string, salary double, department_id int\"\n",
    "\n",
    "emp = spark.read.format(\"csv\").schema(_schema).option(\"header\", True).load(\"/data/input/employee_records_skewed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d8df89-6d6a-4e10-99d5-560f8ea0b3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read DEPT CSV data\n",
    "_dept_schema = \"department_id int, department_name string, description string, city string, state string, country string\"\n",
    "\n",
    "dept = spark.read.format(\"csv\").schema(_dept_schema).option(\"header\", True).load(\"/data/input/department_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba90ff0-a0dc-4a20-bd84-c2389d4ca147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Join Datasets\n",
    "\n",
    "df_joined = emp.join(dept, on=emp.department_id==dept.department_id, how=\"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b613ce-a32a-44d4-bba2-1fa88753df0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_joined.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d15de-b612-433b-8775-6f5f88b27da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explain Plan\n",
    "\n",
    "df_joined.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50625a07-db99-4803-a39e-68707085bfbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|partition_num| count|\n",
      "+-------------+------+\n",
      "|          103| 19860|\n",
      "|          122|420474|\n",
      "|           43| 19899|\n",
      "|          107| 19928|\n",
      "|           49| 20006|\n",
      "|           51| 19829|\n",
      "|          102| 20099|\n",
      "|           66| 20172|\n",
      "|          174| 20229|\n",
      "|           89|419504|\n",
      "+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the partition details to understand distribution\n",
    "from pyspark.sql.functions import spark_partition_id, count, lit\n",
    "\n",
    "part_df = df_joined.withColumn(\"partition_num\", spark_partition_id()).groupBy(\"partition_num\").agg(count(lit(1)).alias(\"count\"))\n",
    "\n",
    "part_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62d80db9-18c9-459e-a1a5-8b395184dde2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|department_id|count(1)|\n",
      "+-------------+--------+\n",
      "|            1|   19899|\n",
      "|            6|   20006|\n",
      "|            3|   19829|\n",
      "|            5|   20172|\n",
      "|            9|  419504|\n",
      "|            4|   20099|\n",
      "|            8|   19860|\n",
      "|            7|   19928|\n",
      "|           10|  420474|\n",
      "|            2|   20229|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify Employee data based on department_id\n",
    "from pyspark.sql.functions import count, lit, desc, col\n",
    "\n",
    "emp.groupBy(\"department_id\").agg(count(lit(1))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "409a7d44-5f4f-4301-9d4f-6e627334d529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set shuffle partitions to a lesser number - 16\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5d20825-28f4-4fef-99a8-9c65a64f73e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 15|\n",
      "| 16|\n",
      "| 17|\n",
      "| 18|\n",
      "| 19|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let prepare the salt\n",
    "import random\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# UDF to return a random number every time and add to Employee as salt\n",
    "@udf\n",
    "def salt_udf():\n",
    "    return random.randint(0, 32)\n",
    "\n",
    "# Salt Data Frame to add to department\n",
    "salt_df = spark.range(0, 32)\n",
    "salt_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a51cc0a-43bd-4cba-8996-8eece7d97045",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+----------+--------------------+--------------------+--------+-------------+--------------+\n",
      "|first_name|last_name|           job_title|       dob|               email|               phone|  salary|department_id|salted_dept_id|\n",
      "+----------+---------+--------------------+----------+--------------------+--------------------+--------+-------------+--------------+\n",
      "|  Samantha|    Brown|Diagnostic radiog...|1966-06-11| jwatson@example.com|       (428)806-5154|439679.0|            3|           3_5|\n",
      "|    Justin|Castaneda|Human resources o...|1996-11-11|  sdavis@example.org|    001-581-642-9621| 97388.0|            4|          4_23|\n",
      "|      Carl| Peterson|         Proofreader|1984-11-23|andrew20@example.net|   241-871-9102x3835|287728.0|            1|           1_5|\n",
      "| Catherine|     Lane|    Location manager|1966-06-21|elizabethalexande...|   470.866.4415x0739|174151.0|            3|          3_25|\n",
      "|     Aaron|  Delgado|Teacher, secondar...|1972-10-11|uwilliams@example...|   384.336.5759x4831|209013.0|            8|          8_17|\n",
      "|  Michelle|     Hill|Customer service ...|1984-01-15|antoniojoseph@exa...|    368.485.0685x793|764126.0|            8|          8_15|\n",
      "|  Kristina|   Martin|       IT consultant|1964-02-23|autumn05@example.com|       (625)327-0615|563768.0|            1|           1_9|\n",
      "|     Carol|  Nichols|      Phytotherapist|1969-02-14|crawfordsarah@exa...|  422-490-1069x38089|156689.0|           10|         10_19|\n",
      "|     Peter|     Hill|      Cytogeneticist|1964-09-23|   xholt@example.org|        935.573.8160|957436.0|            5|          5_23|\n",
      "|  Benjamin|    Lopez|Agricultural engi...|1966-01-20|  ryan46@example.org| +1-256-376-8069x339|891725.0|            1|           1_5|\n",
      "|     Susan|   Savage|Optician, dispensing|1996-07-27|taylorjoshua@exam...| +1-393-821-5515x816|198396.0|            6|           6_5|\n",
      "|    Robert|      Cox|Occupational ther...|1993-06-27|anthony00@example...|          8008487748|907659.0|            3|          3_32|\n",
      "|      Evan|    Terry|Local government ...|1982-01-03|srodriguez@exampl...|        220-913-4625|693419.0|            5|           5_9|\n",
      "|    Justin| Santiago|                Make|1965-03-20| birdjoe@example.org|        801-317-7926|815251.0|            7|           7_9|\n",
      "|      Rose|  Gregory|           Barrister|1974-10-31|samuel27@example.net|        923-304-9438|673811.0|            2|           2_6|\n",
      "|  Nicholas|    Short|  Charity fundraiser|1998-10-03| brian12@example.com|        855.973.7301|538901.0|            4|          4_10|\n",
      "|      John|   Hanson|Lecturer, higher ...|2001-04-12|  zweiss@example.org|       (453)740-2558|247223.0|            7|          7_16|\n",
      "|     Bryan|   Turner|Public relations ...|1984-01-30|  ssmith@example.com|  426.547.0413x20201|286799.0|            6|          6_21|\n",
      "|     Tonya|  Schultz|Contracting civil...|1982-05-07|douglas54@example...|        578-916-7661|664105.0|            4|          4_21|\n",
      "|  Patricia| Anderson|        Set designer|1974-09-22|joshua92@example.net|001-765-729-3973x...|439446.0|            2|          2_21|\n",
      "+----------+---------+--------------------+----------+--------------------+--------------------+--------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Salted Employee\n",
    "from pyspark.sql.functions import lit, concat\n",
    "\n",
    "salted_emp = emp.withColumn(\"salted_dept_id\", concat(\"department_id\", lit(\"_\"), salt_udf()))\n",
    "\n",
    "salted_emp.show()                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ba7f520-7b49-4473-9171-2b4281bbd3da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+-----------+-----+-------+---+--------------+\n",
      "|department_id|     department_name|         description|       city|state|country| id|salted_dept_id|\n",
      "+-------------+--------------------+--------------------+-----------+-----+-------+---+--------------+\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy|  0|           9_0|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy|  1|           9_1|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy|  2|           9_2|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy|  3|           9_3|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy|  4|           9_4|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy|  5|           9_5|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy|  6|           9_6|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy|  7|           9_7|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy|  8|           9_8|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy|  9|           9_9|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy| 10|          9_10|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy| 11|          9_11|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy| 12|          9_12|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy| 13|          9_13|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy| 14|          9_14|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy| 15|          9_15|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy| 16|          9_16|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy| 17|          9_17|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy| 18|          9_18|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|Marychester|   MN|  Italy| 19|          9_19|\n",
      "+-------------+--------------------+--------------------+-----------+-----+-------+---+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Salted Department\n",
    "\n",
    "salted_dept = dept.join(salt_df, how=\"cross\").withColumn(\"salted_dept_id\", concat(\"department_id\", lit(\"_\"), \"id\"))\n",
    "\n",
    "salted_dept.where(\"department_id = 9\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94a09602-ccb0-44df-957e-a5ca7b193805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets make the salted join now\n",
    "salted_joined_df = salted_emp.join(salted_dept, on=salted_emp.salted_dept_id==salted_dept.salted_dept_id, how=\"left_outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab8c0bf-ee79-4f88-bf89-38a17c6d24a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edfbd1c8-5617-4a4b-9c88-97de98079271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "salted_joined_df.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ebe5989-fe90-4d6b-9645-6534ba497354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|partition_num|count|\n",
      "+-------------+-----+\n",
      "|           18|30975|\n",
      "|           12|28636|\n",
      "|           10|17942|\n",
      "|           27|58641|\n",
      "|            1|28039|\n",
      "|            3|31642|\n",
      "|           20|29552|\n",
      "|           29| 4860|\n",
      "|           13|20105|\n",
      "|           14|18831|\n",
      "|           23|81155|\n",
      "|            6|18818|\n",
      "|            9|55094|\n",
      "|           11|44418|\n",
      "|           26| 3006|\n",
      "|            7|30275|\n",
      "|           30| 4220|\n",
      "|           28|16504|\n",
      "|            0|30887|\n",
      "|            8|30997|\n",
      "+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the partition details to understand distribution\n",
    "from pyspark.sql.functions import spark_partition_id, count\n",
    "\n",
    "part_df = salted_joined_df.withColumn(\"partition_num\", spark_partition_id()).groupBy(\"partition_num\").agg(count(lit(1)).alias(\"count\"))\n",
    "\n",
    "part_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a30325-65a3-4c65-a499-38147e42ce50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
